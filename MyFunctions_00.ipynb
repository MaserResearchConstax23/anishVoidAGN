{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62872d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start small and save your time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c23d4fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import pandas as pd # for working with tables\n",
    "pd.options.mode.chained_assignment = None  # default = 'warn'\n",
    "\n",
    "import os # for finding file directory with os.getcwd()\n",
    "from datetime import datetime\n",
    "\n",
    "# for calculations\n",
    "import numpy as np \n",
    "import math\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "\n",
    "# for plotting histogram with percentages\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from PIL import Image # for converting plots to black-and-white\n",
    "from IPython.display import HTML\n",
    "import statistics\n",
    "\n",
    "# from ipynb.fs.full.MyFunctions_00 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13edb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/5 # no default integer division!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e139e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' == 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35cd9de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframes from local .csv files\n",
    "\n",
    "def read_data_old(file_string):\n",
    "    # arguments: a filename string\n",
    "    # returns: table containing data from the corresponding .csv file in my Dropbox\n",
    "    \n",
    "    mac = True # change depending on Windows/Mac operating system\n",
    "    \n",
    "    # finds whether the file is in the \"Voids\" or \"Walls\" folder\n",
    "    if 'VOID' in file_string: folder = 'Voids'\n",
    "    else: folder = 'Walls'\n",
    "    \n",
    "    if(mac):\n",
    "#         file = pd.read_csv('/Users/anisharadhey/Dropbox/AstroSummer22/Data/'\n",
    "#                            + folder + '/' + file_string + '.csv')\n",
    "          file = pd.read_csv('/Users/anisharadhey/Dropbox/voids_Anish/Data/'\n",
    "                           + folder + '/' + file_string + '.csv')\n",
    "    else:\n",
    "        file = pd.read_csv('\\\\Users\\\\smara\\\\Dropbox\\\\AstroSummer22\\\\Data\\\\'\n",
    "                           + folder + '\\\\' + file_string + '.csv')\n",
    "    return(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a39a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframes from local .csv files from a Mac computer\n",
    "\n",
    "def read_data(file_string):\n",
    "    # arguments: a filename string\n",
    "    # returns: table containing data from the corresponding .csv file in local computer folder\n",
    "    \n",
    "    file = pd.read_csv('/Users/anisharadhey/AstroLocal22/' + file_string + '.csv')\n",
    "    print('read ' + file_string)\n",
    "        \n",
    "    return(file)\n",
    "\n",
    "def read_data_db(file_string):\n",
    "    # arguments: a filename string\n",
    "    # returns: table containing data from the corresponding .csv file in Dropbox folder\n",
    "    \n",
    "#     file = pd.read_csv('/Users/anisharadhey/Dropbox/AstroSummer22/Code/' + file_string + '.csv')\n",
    "    \n",
    "    file = pd.read_csv('/Users/anisharadhey/Dropbox/voids_Anish/anishVoidAGN/Files/' + file_string + '.csv')\n",
    "    print('read ' + file_string)\n",
    "        \n",
    "    return(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cb6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_code(file_string):\n",
    "    # arguments: a filename string\n",
    "    # returns: table containing data from the corresponding .csv file in Dropbox folder\n",
    "    \n",
    "#     file = pd.read_csv('/Users/anisharadhey/Dropbox/AstroSummer22/Code/' + file_string + '.csv')\n",
    "    \n",
    "    file = pd.read_csv('/Users/anisharadhey/Dropbox/voids_Anish/anishVoidAGN/' + file_string + '.csv')\n",
    "    print('read ' + file_string)\n",
    "        \n",
    "    return(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554e9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(NEO_full, ME_full):\n",
    "    # arguments: dataframes for one group from NEOWISE and MEP\n",
    "    # returns: dataframe containing rows from both NEOWISE and MEP tables with standardized columns\n",
    "\n",
    "    # filter by SNR to keep only higher values\n",
    "    # for the multi-epoch data, we estimate SNR using the inverse of uncertainty in magnitudes\n",
    "    \n",
    "    NEO_filt = NEO_full[(NEO_full['w1snr'] >= 5) & \n",
    "                        (NEO_full['w2snr'] >= 5)]\n",
    "    \n",
    "    ME_full['w1snr_est'] = ME_full.w1mpro_ep / ME_full.w1sigmpro_ep\n",
    "    ME_full['w2snr_est'] = ME_full.w2mpro_ep / ME_full.w2sigmpro_ep\n",
    "    \n",
    "    ME_filt = ME_full[(ME_full['w1snr_est'] >= 5) & \n",
    "                      (ME_full['w2snr_est'] >= 5)]\n",
    "    \n",
    "    # remove unecessary columns and rename other so that NEO and MEP match\n",
    "    \n",
    "    NEO_cols = NEO_filt[[\"object_tag_01\", \"w1mpro\", \"w2mpro\", \"mjd\"]].rename(\n",
    "        columns = {\"object_tag_01\": \"object_tag\"})\n",
    "\n",
    "    ME_cols = ME_filt[[\"object_tag_01\", \"w1mpro_ep\", \"w2mpro_ep\", \"mjd\"]].rename(\n",
    "        columns = {\"object_tag_01\": \"object_tag\", \"w1mpro_ep\": \"w1mpro\", \"w2mpro_ep\": \"w2mpro\"})\n",
    "\n",
    "    full = pd.concat([NEO_cols, ME_cols], ignore_index = True)\n",
    "\n",
    "    return(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9896f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_new(NEO_full, ME_full):\n",
    "    # arguments: dataframes for one group from NEOWISE and MEP\n",
    "    # returns: dataframe containing rows from both NEOWISE and MEP tables with standardized columns\n",
    "\n",
    "    # filter by SNR to keep only higher values\n",
    "    # for the multi-epoch data, we estimate SNR using the inverse of uncertainty in magnitudes\n",
    "    \n",
    "    NEO_filt = NEO_full[(NEO_full['w1snr'] >= 5) & \n",
    "                        (NEO_full['w2snr'] >= 5)]\n",
    "    \n",
    "    ME_full['w1snr_est'] = ME_full.w1mpro_ep / ME_full.w1sigmpro_ep\n",
    "    ME_full['w2snr_est'] = ME_full.w2mpro_ep / ME_full.w2sigmpro_ep\n",
    "    \n",
    "    ME_filt = ME_full[(ME_full['w1snr_est'] >= 5) & \n",
    "                      (ME_full['w2snr_est'] >= 5)]\n",
    "    \n",
    "    # remove unecessary columns and rename other so that NEO and MEP match\n",
    "    \n",
    "    NEO_cols = NEO_filt[[\"nsaid_01\", \"w1mpro\", \"w2mpro\", \"mjd\"]]\n",
    "    NEO_cols['object_tag'] = NEO_cols['nsaid_01']\n",
    "    NEO_cols['origin'] = 'NEO'\n",
    "\n",
    "    ME_cols = ME_filt[[\"nsaid_01\", \"w1mpro_ep\", \"w2mpro_ep\", \"mjd\"]].rename(\n",
    "        columns = {\"w1mpro_ep\": \"w1mpro\", \"w2mpro_ep\": \"w2mpro\"})\n",
    "    ME_cols['object_tag'] = ME_cols['nsaid_01']\n",
    "    ME_cols['origin'] = 'MEP'\n",
    "    # ABOVE: changed to ME_cols from NEO_cols on 6-12-2023\n",
    "\n",
    "    full = pd.concat([NEO_cols, ME_cols], ignore_index = True)\n",
    "\n",
    "    return(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9cb337a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_new_colors(NEO_full, ME_full, filtered_cols):\n",
    "    # arguments: dataframes for one group from NEOWISE and MEP\n",
    "    # returns: dataframe containing rows from both NEOWISE and MEP tables with standardized columns\n",
    "\n",
    "    # filter by SNR to keep only higher values\n",
    "    # for the multi-epoch data, we estimate SNR using the inverse of uncertainty in magnitudes\n",
    "    \n",
    "    print(len(np.unique(NEO_full['nsaid_01'].tolist() + ME_full['nsaid_01'].tolist())))\n",
    "    \n",
    "    NEO_filt = NEO_full[(NEO_full['w1snr'] >= 5) & \n",
    "                        (NEO_full['w2snr'] >= 5)]\n",
    "    \n",
    "    ME_full['w1snr_est'] = ME_full.w1mpro_ep / ME_full.w1sigmpro_ep\n",
    "    ME_full['w2snr_est'] = ME_full.w2mpro_ep / ME_full.w2sigmpro_ep\n",
    "    \n",
    "    ME_filt = ME_full[(ME_full['w1snr_est'] >= 5) & \n",
    "                      (ME_full['w2snr_est'] >= 5)]\n",
    "    \n",
    "    print(len(np.unique(NEO_filt['nsaid_01'].tolist() + ME_filt['nsaid_01'].tolist())))\n",
    "    \n",
    "    # remove unecessary columns and rename other so that NEO and MEP match\n",
    "    \n",
    "    NEO_cols = NEO_filt[[\"nsaid_01\", \"w1mpro\", \"w2mpro\", \"mjd\"]]\n",
    "    NEO_cols['object_tag'] = NEO_cols['nsaid_01']\n",
    "    NEO_cols['origin'] = 'NEO'\n",
    "\n",
    "    ME_cols = ME_filt[[\"nsaid_01\", \"w1mpro_ep\", \"w2mpro_ep\", \"mjd\"]].rename(\n",
    "        columns = {\"w1mpro_ep\": \"w1mpro\", \"w2mpro_ep\": \"w2mpro\"})\n",
    "    ME_cols['object_tag'] = ME_cols['nsaid_01']\n",
    "    ME_cols['origin'] = 'MEP'\n",
    "    # ABOVE: changed to ME_cols from NEO_cols on 6-12-2023\n",
    "\n",
    "    full = pd.concat([NEO_cols, ME_cols], ignore_index = True)\n",
    "    \n",
    "    full_merged = full.merge(filtered_cols, \n",
    "                                   how = 'left', \n",
    "                                   on = 'object_tag')\n",
    "    \n",
    "    full_merged['W2_diff'] = abs(full_merged.w2mpro -\n",
    "                                   full_merged.w2mpro_AWS)\n",
    "    \n",
    "    print(len(np.unique(full_merged['object_tag'])))\n",
    "    print(len(full_merged))\n",
    "    \n",
    "    # not filtering out 1 mag deviations for all measurements, just quantifying for very faint W2 objects\n",
    "    full_merged_filt = full_merged # [full_merged['W2_diff'] <= 1.0]\n",
    "\n",
    "    print(len(full_merged_filt))\n",
    "    print(len(np.unique(full_merged_filt['object_tag'])))\n",
    "    \n",
    "    full_merged_filt_na = full_merged_filt.dropna(axis = 'index',\n",
    "                                                  how = 'any',\n",
    "                                                  subset = [\n",
    "                                                      'w1mpro',\n",
    "                                                      'w2mpro',\n",
    "                                                      'mjd',\n",
    "                                                      'object_tag',\n",
    "                                                      'origin'\n",
    "                                                  ]\n",
    "                                                 )\n",
    "    \n",
    "    print(len(np.unique(full_merged_filt_na['object_tag'])))\n",
    "\n",
    "    return(full_merged_filt_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7d4a983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13b98628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3] + [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d5531f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def expand_cols(full, tag_num):\n",
    "    # arguments: dataframe of combined NEOWISE and MEP data + desired object tag\n",
    "    # returns: same dataframe with columns for mjd starting at 0, W1-W2 color, bin #, and mjd_binned.\n",
    "    #          the dataframe will only contain rows with the indicated object tag.\n",
    "    # filter dataframe to only get rows for the specific object\n",
    "    \n",
    "    tag = tag_num\n",
    "    full_tag = full[(full['object_tag'] == tag)]\n",
    "\n",
    "    # within the rows for the specific object, subtract from the mjds so that the earliest date is 0 days\n",
    "    min_mjd = full_tag['mjd'].min()\n",
    "    full_tag['mjd_zero'] = full_tag['mjd'] - min_mjd\n",
    "\n",
    "    # add column for W1 - W2 color\n",
    "    full_tag['W1-W2'] = full_tag.w1mpro - full_tag.w2mpro\n",
    "    \n",
    "    # bin the data (resource: https://stackoverflow.com/questions/6163334/binning-data-in-python-with-scipy-numpy)\n",
    "    mjd_full = full_tag['mjd_zero']\n",
    "    data = mjd_full.to_numpy()\n",
    "    bins = np.arange(start = 10, stop = int(mjd_full.max()) + 11, step = 10) # each bins is 10 days\n",
    "    bin_num = np.digitize(data, bins, right = True) # returns the bin index for each data item\n",
    "    # bins[i-1] < x <= bins[i]\n",
    "\n",
    "    # add a bin number to the dataframe\n",
    "    full_tag['bin_num'] = bin_num\n",
    "    \n",
    "    # define x values to plot the data as the center of the bins\n",
    "    # based on the bin number, assign each observation a centered mjd value for plotting\n",
    "#     print(bins)\n",
    "    xs = np.arange(start = 5, stop = bins.max() + 10, step = 10)\n",
    "    full_tag['mjd_binned'] = xs[full_tag['bin_num']]\n",
    "    \n",
    "    return(full_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acad358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_binned(full_tag, tag_num):\n",
    "    # arguments: dataframe of expanded column data for one group and one object tag\n",
    "    # returns: table with mean W1, W2, and color (with associated erors) for each filled bin in the argument table\n",
    "\n",
    "    # make an empty mean table with standard deviations\n",
    "    mean_table = pd.DataFrame(columns = ['object_tag', 'mjd_binned', \n",
    "                                         'mean_W1', 'mean_W2', 'mean_color',\n",
    "                                         'std_W1', 'std_W2', 'std_color'])\n",
    "\n",
    "    # for each unique centered mjd value...\n",
    "    for x in np.unique(full_tag['mjd_binned']):\n",
    "\n",
    "        # get the rows from the expanded dataframe that have that mjd binned value\n",
    "        temp = full_tag[(full_tag['mjd_binned'] == x)]\n",
    "\n",
    "        # calculate the means of the measurements as well as the associated errors\n",
    "        # this will be plotted as the point on the light curve for the corresponding bin\n",
    "        mean_W1 = temp['w1mpro'].mean()\n",
    "        mean_W2 = temp['w2mpro'].mean()\n",
    "        mean_diff = temp['W1-W2'].mean()\n",
    "\n",
    "        std_W1 = np.std(temp['w1mpro'])\n",
    "        std_W2 = np.std(temp['w2mpro'])\n",
    "        std_diff = np.std(temp['W1-W2'])\n",
    "\n",
    "        # add this information as a row to the mean table\n",
    "        # the mean table will contain a row for each unique centered mjd position\n",
    "        # this will contain all of the information needed to plot a light curve\n",
    "        mean_table.loc[len(mean_table.index)] = [tag_num, \n",
    "                                                 int(x), \n",
    "                                                 mean_W1, mean_W2, mean_diff, \n",
    "                                                 std_W1, std_W2, std_diff]\n",
    "        \n",
    "    return(mean_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4674a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50000025"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([1, 0.0000005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28842881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_binned_outliers(full_tag, tag_num):\n",
    "    \n",
    "    mean_table = pd.DataFrame(columns = ['object_tag', 'mjd_binned', \n",
    "                                     'mean_W1', 'mean_W2', 'mean_color',\n",
    "                                     'std_W1', 'std_W2', 'std_color', \n",
    "                                     'mad_W1', 'mad_W2', 'origin_binned', \n",
    "                                        'removed_mad', 'num_measure', 'num_measure_mag1'])\n",
    "    \n",
    "    outliers_removed_table = pd.DataFrame(columns = ['nsaid_01',\n",
    "                                                     'w1mpro',\n",
    "                                                     'w2mpro',\n",
    "                                                     'mjd',\n",
    "                                                     'object_tag',\n",
    "                                                     'origin',\n",
    "                                                     'w1mpro_AWS',\n",
    "                                                     'w2mpro_AWS',\n",
    "                                                     'W2_diff',\n",
    "                                                     'mjd_zero',\n",
    "                                                     'W1-W2',\n",
    "                                                     'bin_num',\n",
    "                                                     'mjd_binned',\n",
    "                                                     'med_dev_W1',\n",
    "                                                     'med_dev_W2',\n",
    "                                                     'dev_score_W1',\n",
    "                                                     'dev_score_W2'])\n",
    "\n",
    "    for x in np.unique(full_tag['mjd_binned']):\n",
    "        \n",
    "        temp = full_tag[(full_tag['mjd_binned'] == x)]\n",
    "#         print(str(tag_num) + ' bin ' + str(x))\n",
    "\n",
    "        # not the problem lines!! (No errors if we make these 1)\n",
    "    \n",
    "    # NAN should not be a problem at this point because of NA filter in\n",
    "    # combine_new_colors()\n",
    "        med_W1 = np.nanmedian(temp['w1mpro'].to_numpy())\n",
    "        med_W2 = np.nanmedian(temp['w2mpro'].to_numpy()) # tested\n",
    "        \n",
    "#         print(med_W1)\n",
    "#         print(med_W2)\n",
    "\n",
    "        dev_list_W1 = []\n",
    "        dev_list_W2 = []\n",
    "\n",
    "        for i in temp.index:\n",
    "            \n",
    "            dev_list_W1.append(abs(med_W1 - temp['w1mpro'][i]))\n",
    "            dev_list_W2.append(abs(med_W2 - temp['w2mpro'][i]))\n",
    "\n",
    "            # the problem lines! Works if we replace med_W1 with 1 or 0 or -1, even\n",
    "            # when the number is a numpy float, or nan value!!!!\n",
    "#             dev_list_W1.append(abs(np.nan - temp['w1mpro'][i]))\n",
    "#             dev_list_W2.append(abs(np.nan - temp['w2mpro'][i]))\n",
    "        \n",
    "#         print('e')\n",
    "\n",
    "        temp['med_dev_W1'] = dev_list_W1\n",
    "        temp['med_dev_W2'] = dev_list_W2\n",
    "\n",
    "        MAD_W1 = np.nanmedian(dev_list_W1)\n",
    "        MAD_W2 = np.nanmedian(dev_list_W2)\n",
    "\n",
    "        dev_scores_W1 = []\n",
    "        dev_scores_W2 = []\n",
    "\n",
    "        for i in temp.index:\n",
    "            dev_scores_W1.append(temp['med_dev_W1'][i] / MAD_W1)\n",
    "            dev_scores_W2.append(temp['med_dev_W2'][i] / MAD_W2)\n",
    "            \n",
    "\n",
    "        temp['dev_score_W1'] = dev_scores_W1\n",
    "        temp['dev_score_W2'] = dev_scores_W2\n",
    "\n",
    "        temp_cleaned = temp[(temp['dev_score_W1'] <= 3) &\n",
    "                            (temp['dev_score_W2'] <= 3)]\n",
    "\n",
    "        mean_W1 = temp_cleaned['w1mpro'].mean()\n",
    "        mean_W2 = temp_cleaned['w2mpro'].mean()\n",
    "        mean_diff = temp_cleaned['W1-W2'].mean()\n",
    "\n",
    "        std_W1 = np.std(temp_cleaned['w1mpro'])\n",
    "        std_W2 = np.std(temp_cleaned['w2mpro'])\n",
    "        std_diff = np.std(temp_cleaned['W1-W2'])\n",
    "\n",
    "        org_bin = ''.join(np.unique(temp_cleaned['origin']))\n",
    "        \n",
    "        # Not the problem\n",
    "        mad_W1 = scipy.stats.median_abs_deviation(temp_cleaned['w1mpro'],\n",
    "                                                  nan_policy = 'raise')\n",
    "        mad_W2 = scipy.stats.median_abs_deviation(temp_cleaned['w2mpro'],\n",
    "                                                  nan_policy = 'raise')\n",
    "        \n",
    "        removed = len(temp) - len(temp_cleaned)\n",
    "        num_mes = len(temp_cleaned)\n",
    "        \n",
    "        mag1_W2 = len(temp[temp['W2_diff'] > 1.0])\n",
    "    \n",
    "        mean_table.loc[len(mean_table.index)] = [tag_num,\n",
    "                                                 int(x),\n",
    "                                                 mean_W1, mean_W2, mean_diff,\n",
    "                                                 std_W1, std_W2, std_diff,\n",
    "                                                 mad_W1, mad_W2, org_bin, removed,\n",
    "                                                 num_mes, mag1_W2]\n",
    "        \n",
    "        outliers_removed_table = pd.concat([outliers_removed_table, \n",
    "                                            temp_cleaned], \n",
    "                                            ignore_index = True)\n",
    "#         print('finished')\n",
    "\n",
    "    return(mean_table, outliers_removed_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9009d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nsaid_01</th>\n",
       "      <th>w1mpro</th>\n",
       "      <th>w2mpro</th>\n",
       "      <th>mjd</th>\n",
       "      <th>object_tag</th>\n",
       "      <th>origin</th>\n",
       "      <th>w1mpro_AWS</th>\n",
       "      <th>w2mpro_AWS</th>\n",
       "      <th>W2_diff</th>\n",
       "      <th>mjd_zero</th>\n",
       "      <th>W1-W2</th>\n",
       "      <th>bin_num</th>\n",
       "      <th>mjd_binned</th>\n",
       "      <th>med_dev_W1</th>\n",
       "      <th>med_dev_W2</th>\n",
       "      <th>dev_score_W1</th>\n",
       "      <th>dev_score_W2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nsaid_01, w1mpro, w2mpro, mjd, object_tag, origin, w1mpro_AWS, w2mpro_AWS, W2_diff, mjd_zero, W1-W2, bin_num, mjd_binned, med_dev_W1, med_dev_W2, dev_score_W1, dev_score_W2]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAN return tuple with two pd Dataframes!\n",
    "\n",
    "def test_double():\n",
    "    \n",
    "    b = pd.DataFrame(columns = ['object_tag', 'mjd_binned', \n",
    "                                     'mean_W1', 'mean_W2', 'mean_color',\n",
    "                                     'std_W1', 'std_W2', 'std_color', \n",
    "                                     'mad_W1', 'mad_W2', 'origin_binned', \n",
    "                                        'removed_mad', 'num_measure'])\n",
    "    \n",
    "    a = pd.DataFrame(columns = ['nsaid_01',\n",
    "                                'w1mpro',\n",
    "                                'w2mpro',\n",
    "                                'mjd',\n",
    "                                'object_tag',\n",
    "                                'origin',\n",
    "                                'w1mpro_AWS',\n",
    "                                'w2mpro_AWS',\n",
    "                                'W2_diff',\n",
    "                                'mjd_zero',\n",
    "                                'W1-W2',\n",
    "                                'bin_num',\n",
    "                                'mjd_binned',\n",
    "                                'med_dev_W1',\n",
    "                                'med_dev_W2',\n",
    "                                'dev_score_W1',\n",
    "                                'dev_score_W2'])\n",
    "    return(b, a)\n",
    "\n",
    "c = test_double()\n",
    "type(c)\n",
    "c[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67b38cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_err(x, y):\n",
    "    # arguments: any quantity with a dividend and divisor\n",
    "    # returns: a string containing the associated error for the quotient\n",
    "    \n",
    "    num_error = math.sqrt((1 / x) + (1 / y))\n",
    "    return \" Â± \" + str(round(num_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bde8427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_err_num(x, y):\n",
    "    # arguments: any quantity with a dividend and divisor\n",
    "    # returns: a string containing the associated error for the quotient\n",
    "    \n",
    "    num_error = math.sqrt((1.0 / x) + (1.0 / y))\n",
    "    return num_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "965e6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_table(ultimate_mean, sig):\n",
    "    # arguments = \n",
    "    # returns = \n",
    "\n",
    "    outlier_table = pd.DataFrame(columns = ['object_tag', \n",
    "                                            'mjd_binned', \n",
    "                                            'mean_W1', \n",
    "                                            'mean_W2', \n",
    "                                            'mean_color', \n",
    "                                            'std_W1', \n",
    "                                            'std_W2', \n",
    "                                            'std_color'])\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    for t in np.unique(ultimate_mean['object_tag']):\n",
    "\n",
    "        ultimate_t = ultimate_mean[(ultimate_mean['object_tag'] == t)]\n",
    "        \n",
    "        num_bins = len(ultimate_t)\n",
    "        \n",
    "        if (num_bins > 3):\n",
    "            \n",
    "            W1_mean = ultimate_t['mean_W1'].mean()\n",
    "            W2_mean = ultimate_t['mean_W2'].mean()\n",
    "\n",
    "            W1_std = np.std(ultimate_t['mean_W1'])\n",
    "            W2_std = np.std(ultimate_t['mean_W2'])\n",
    "            \n",
    "            outliers_removed = ultimate_t[\n",
    "                (ultimate_t['mean_W1'] <= W1_mean + (sig * W1_std)) &\n",
    "                (ultimate_t['mean_W1'] >= W1_mean - (sig * W1_std)) &\n",
    "                (ultimate_t['mean_W2'] <= W2_mean + (sig * W2_std)) &\n",
    "                (ultimate_t['mean_W2'] >= W2_mean - (sig * W2_std))\n",
    "            ]\n",
    "            \n",
    "            if (len(outliers_removed) > 0):\n",
    "                outlier_table = pd.concat([outlier_table, outliers_removed], ignore_index = True)\n",
    "                \n",
    "        count += 1\n",
    "        \n",
    "        if(count % 5000 == 0):\n",
    "            print(str(count) + ' galaxies')\n",
    "        \n",
    "    return(outlier_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b5d5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No longer needed after we switch location of outlier-removing code!\n",
    "\n",
    "def outlier_table_switched(ultimate_mean, sig):\n",
    "    # arguments = \n",
    "    # returns = \n",
    "\n",
    "    outlier_table = pd.DataFrame(columns = ['object_tag', \n",
    "                                            'mjd_binned', \n",
    "                                            'mean_W1', \n",
    "                                            'mean_W2', \n",
    "                                            'mean_color', \n",
    "                                            'std_W1', \n",
    "                                            'std_W2', \n",
    "                                            'std_color'])\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    for t in np.unique(ultimate_mean['object_tag']):\n",
    "\n",
    "        ultimate_t = ultimate_mean[(ultimate_mean['object_tag'] == t)]\n",
    "        \n",
    "        num_bins = len(ultimate_t)\n",
    "        \n",
    "        W1_mean = ultimate_t['mean_W1'].mean()\n",
    "        W2_mean = ultimate_t['mean_W2'].mean()\n",
    "\n",
    "        W1_std = np.std(ultimate_t['mean_W1'])\n",
    "        W2_std = np.std(ultimate_t['mean_W2'])\n",
    "        \n",
    "        outliers_removed = ultimate_t[\n",
    "                (ultimate_t['mean_W1'] <= W1_mean + (sig * W1_std)) &\n",
    "                (ultimate_t['mean_W1'] >= W1_mean - (sig * W1_std)) &\n",
    "                (ultimate_t['mean_W2'] <= W2_mean + (sig * W2_std)) &\n",
    "                (ultimate_t['mean_W2'] >= W2_mean - (sig * W2_std))\n",
    "            ]\n",
    "        \n",
    "        if (len(outliers_removed) > 3):\n",
    "            \n",
    "            outlier_table = pd.concat([outlier_table, outliers_removed], ignore_index = True)\n",
    "                \n",
    "        count += 1\n",
    "        \n",
    "        if(count % 5000 == 0):\n",
    "            print(str(count) + ' galaxies')\n",
    "        \n",
    "    return(outlier_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42c64ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_curve(t, full, save):\n",
    "    # plot light curve for a given object\n",
    "    # enter object tag for the desired object\n",
    "    # generate all columns and binned data for that object\n",
    "    \n",
    "    full_tag = expand_cols(full, t)\n",
    "    mean = save_binned(full_tag, t)\n",
    "\n",
    "    # define three vertically-stackd subplots\n",
    "    fig, axs = plt.subplots(3, 1, \n",
    "                            figsize = (16, 10),\n",
    "                            sharex = 'col', \n",
    "                            sharey = 'row'\n",
    "                           )\n",
    "\n",
    "    plt.subplots_adjust(wspace = 0, hspace = 0)\n",
    "\n",
    "    # add title that automatically includes the name of the plotted object\n",
    "    fig.suptitle('WISE light curve of void galaxy (object tag = ' + str(t) + \")\", fontsize = 'x-large')\n",
    "\n",
    "    # scatter individual measurements using the full_tag table\n",
    "    # different colors and bands are used for each subplot\n",
    "    axs[0].scatter(full_tag['mjd_binned'], \n",
    "                   full_tag['w1mpro'], \n",
    "                   s = 15, \n",
    "                   c = 'dimgray',\n",
    "                   marker = \"o\",\n",
    "                   alpha = 0.3)\n",
    "\n",
    "    axs[1].scatter(full_tag['mjd_binned'], \n",
    "                   full_tag['w2mpro'], \n",
    "                   s = 15, \n",
    "                   c = 'dimgray',\n",
    "                   marker = \"o\",\n",
    "                   alpha = 0.3)\n",
    "\n",
    "    axs[2].scatter(full_tag['mjd_binned'], \n",
    "                   full_tag['W1-W2'], \n",
    "                   s = 15, \n",
    "                   c = 'dimgray',\n",
    "                   marker = \"o\",\n",
    "                   alpha = 0.3)\n",
    "\n",
    "    # scatter the mean points on top of the individual measurements, all on the same binned x-values\n",
    "    axs[0].scatter(mean['mjd_binned'], \n",
    "                   mean['mean_W1'], \n",
    "                   s = 65, \n",
    "                   c = 'dodgerblue',\n",
    "                   marker = \"s\")\n",
    "\n",
    "    axs[1].scatter(mean['mjd_binned'], \n",
    "                   mean['mean_W2'], \n",
    "                   s = 65, \n",
    "                   c = 'dodgerblue',\n",
    "                   marker = \"s\")\n",
    "\n",
    "    axs[2].scatter(mean['mjd_binned'], \n",
    "                   mean['mean_color'], \n",
    "                   s = 65, \n",
    "                   c = 'dodgerblue',\n",
    "                   marker = \"s\")\n",
    "\n",
    "    # add error bars for means using the standard deviations calculated in the mean table\n",
    "    axs[0].errorbar(mean['mjd_binned'], \n",
    "                    mean['mean_W1'],\n",
    "                    yerr = mean['std_W1'],\n",
    "                    c = \"dodgerblue\",\n",
    "                    ecolor = \"dodgerblue\",\n",
    "                    capsize = 4,\n",
    "                    fmt = \"o\")\n",
    "\n",
    "    axs[1].errorbar(mean['mjd_binned'], \n",
    "                    mean['mean_W2'],\n",
    "                    yerr = mean['std_W2'],\n",
    "                    c = \"dodgerblue\",\n",
    "                    ecolor = \"dodgerblue\",\n",
    "                    capsize = 4,\n",
    "                    fmt = \"o\")\n",
    "\n",
    "    axs[2].errorbar(mean['mjd_binned'], \n",
    "                    mean['mean_color'],\n",
    "                    yerr = mean['std_color'],\n",
    "                    c = \"dodgerblue\",\n",
    "                    ecolor = \"dodgerblue\",\n",
    "                    capsize = 4,\n",
    "                    fmt = \"o\")\n",
    "\n",
    "    # automatically set the axis limits for the graph based on the range of the plotted data\n",
    "    axs[0].set_xlim([mean['mjd_binned'].min() - 100, mean['mjd_binned'].max() + 100])\n",
    "    axs[0].set_ylim([full_tag['w1mpro'].min() - 0.1, full_tag['w1mpro'].max() + 0.1])\n",
    "    axs[1].set_ylim([full_tag['w2mpro'].min() - 0.1, full_tag['w2mpro'].max() + 0.1])\n",
    "    axs[2].set_ylim([full_tag['W1-W2'].min() - 0.1, full_tag['W1-W2'].max() + 0.1])\n",
    "\n",
    "    # only label the outermost axes\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "\n",
    "    # set all axis labels, including mjd that autmatically includes the value we subtracted in order to start at zero\n",
    "    axs[0].set_ylabel('W1 (mag)', fontsize = 'large')\n",
    "    axs[1].set_ylabel('W2 (mag)', fontsize = 'large')\n",
    "    axs[2].set_ylabel('W1 - W2 (mag)', fontsize = 'large')\n",
    "    axs[2].set_xlabel('MJD - ' + str(full_tag['mjd'].min()), fontsize = 'large')\n",
    "    \n",
    "#     axs[0].set_yticklabels(tick_labels.astype(int))\n",
    "\n",
    "    # save figure in a unique file for each object tag\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    \n",
    "    if(save == True):\n",
    "        fig.savefig('light-curve-' + str(t) + '.pdf', dpi = 300)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59beb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_curve(t, full, g, ax1, ax2, ax3, all_Pr):\n",
    "    # plot light curve for a given object\n",
    "    # enter object tag for the desired object\n",
    "    # generate all columns and binned data for that object\n",
    "    \n",
    "    full_tag = expand_cols(full, t)\n",
    "    mean = save_binned(full_tag, t)\n",
    "    \n",
    "    test_r = all_Pr[(all_Pr['object_tag'] == t)]['Pr']\n",
    "\n",
    "    # add title that automatically includes the name of the plotted object\n",
    "#     ax1.set_title(g + ' object NSAID: ' + str(t) + \" (r = \" + test_r.to_string(index = False) + \")\", \n",
    "#                  fontsize = 'x-large')\n",
    "    ax1.set_title(\"(r = \" + test_r.to_string(index = False) + \")\", \n",
    "                 fontsize = '16')\n",
    "\n",
    "    # scatter individual measurements using the full_tag table\n",
    "    # different colors and bands are used for each subplot\n",
    "    ax1.scatter(full_tag['mjd_binned'], \n",
    "                   full_tag['w1mpro'], \n",
    "                   s = 15, \n",
    "                   c = 'dimgray',\n",
    "                   marker = \"o\",\n",
    "                   alpha = 0.3)\n",
    "\n",
    "    ax2.scatter(full_tag['mjd_binned'], \n",
    "                   full_tag['w2mpro'], \n",
    "                   s = 15, \n",
    "                   c = 'dimgray',\n",
    "                   marker = \"o\",\n",
    "                   alpha = 0.3)\n",
    "\n",
    "    ax3.scatter(full_tag['mjd_binned'], \n",
    "                   full_tag['W1-W2'], \n",
    "                   s = 15, \n",
    "                   c = 'dimgray',\n",
    "                   marker = \"o\",\n",
    "                   alpha = 0.3)\n",
    "\n",
    "    # scatter the mean points on top of the individual measurements, all on the same binned x-values\n",
    "    ax1.scatter(mean['mjd_binned'], \n",
    "                   mean['mean_W1'], \n",
    "                   s = 65, \n",
    "                   c = 'dodgerblue',\n",
    "                   marker = \"s\")\n",
    "\n",
    "    ax2.scatter(mean['mjd_binned'], \n",
    "                   mean['mean_W2'], \n",
    "                   s = 65, \n",
    "                   c = 'dodgerblue',\n",
    "                   marker = \"s\")\n",
    "\n",
    "    ax3.scatter(mean['mjd_binned'], \n",
    "                   mean['mean_color'], \n",
    "                   s = 65, \n",
    "                   c = 'dodgerblue',\n",
    "                   marker = \"s\")\n",
    "\n",
    "    # add error bars for means using the standard deviations calculated in the mean table\n",
    "    ax1.errorbar(mean['mjd_binned'], \n",
    "                    mean['mean_W1'],\n",
    "                    yerr = mean['std_W1'],\n",
    "                    c = \"dodgerblue\",\n",
    "                    ecolor = \"dodgerblue\",\n",
    "                    capsize = 4,\n",
    "                    fmt = \"o\")\n",
    "\n",
    "    ax2.errorbar(mean['mjd_binned'], \n",
    "                    mean['mean_W2'],\n",
    "                    yerr = mean['std_W2'],\n",
    "                    c = \"dodgerblue\",\n",
    "                    ecolor = \"dodgerblue\",\n",
    "                    capsize = 4,\n",
    "                    fmt = \"o\")\n",
    "\n",
    "    ax3.errorbar(mean['mjd_binned'], \n",
    "                    mean['mean_color'],\n",
    "                    yerr = mean['std_color'],\n",
    "                    c = \"dodgerblue\",\n",
    "                    ecolor = \"dodgerblue\",\n",
    "                    capsize = 4,\n",
    "                    fmt = \"o\")\n",
    "\n",
    "    # automatically set the axis limits for the graph based on the range of the plotted data\n",
    "    ax1.set_xlim([mean['mjd_binned'].min() - 100, mean['mjd_binned'].max() + 100])\n",
    "    ax1.set_ylim([full_tag['w1mpro'].min() - 0.1, full_tag['w1mpro'].max() + 0.1])\n",
    "    ax2.set_ylim([full_tag['w2mpro'].min() - 0.1, full_tag['w2mpro'].max() + 0.1])\n",
    "    ax3.set_ylim([full_tag['W1-W2'].min() - 0.1, full_tag['W1-W2'].max() + 0.1])\n",
    "    \n",
    "    ax1.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax2.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax3.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "    # set all axis labels, including mjd that autmatically includes the value we subtracted in order to start at zero\n",
    "    ax3.set_xlabel('MJD - ' + str(full_tag['mjd'].min()), fontsize = 'large')\n",
    "    \n",
    "#     ax1.get_shared_x_axes().join(ax1, ax2)\n",
    "#     ax2.get_shared_x_axes().join(ax2, ax3)\n",
    "#     ax1.set_xticklabels([])\n",
    "#     ax2.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7766eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_mosaic(title_fig, num_v, num_w, voids_full, walls_full, all_Pr, save,):\n",
    "    fig, axs = plt.subplots(3, 2, figsize = (24, 10), sharex = 'col')\n",
    "\n",
    "#     fig.suptitle(title_fig, fontsize = 'x-large')\n",
    "\n",
    "    sub_curve(num_v, voids_full, \"void\", axs[0, 0], axs[1, 0], axs[2, 0], all_Pr)\n",
    "\n",
    "    sub_curve(num_w, walls_full, \"wall\", axs[0, 1], axs[1, 1], axs[2, 1], all_Pr)\n",
    "\n",
    "    axs[0, 0].set_ylabel('W1 (mag)', fontsize = '16')\n",
    "    axs[1, 0].set_ylabel('W2 (mag)', fontsize = '16')\n",
    "    axs[2, 0].set_ylabel('W1 - W2 (mag)', fontsize = '16')\n",
    "\n",
    "    plt.subplots_adjust(wspace = 0.07, hspace = 0)\n",
    "    \n",
    "    if(save == True):\n",
    "        fig.savefig('/Users/anisharadhey/Dropbox/voids_Anish/Figures/curve-mosaic' + str(num_v) + '_' + str(num_w) + '.png', dpi = 600)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "665a1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_mosaic_svrsef(title_fig, num_v, num_w, voids_full, walls_full, all_Pr, save,):\n",
    "    fig, axs = plt.subplots(3, 2, figsize = (12, 5), sharex = 'col')\n",
    "\n",
    "#     fig.suptitle(title_fig, fontsize = 'x-large')\n",
    "\n",
    "#     sub_curve(num_v, voids_full, \"void\", axs[0, 0], axs[1, 0], axs[2, 0], all_Pr)\n",
    "\n",
    "    sub_curve(num_w, walls_full, \"wall\", axs[0, 1], axs[1, 1], axs[2, 1], all_Pr)\n",
    "\n",
    "    axs[0, 0].set_ylabel('W1 (mag)', fontsize = 18)\n",
    "    axs[1, 0].set_ylabel('W2 (mag)', fontsize = 18)\n",
    "    axs[2, 0].set_ylabel('W1 - W2 (mag)', fontsize = 18)\n",
    "\n",
    "    plt.subplots_adjust(wspace = 0.07, hspace = 0)\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "    \n",
    "    if(save == True):\n",
    "        fig.savefig('/Users/anisharadhey/Dropbox/voids_Anish/Figures/curve-mosaic' + str(num_v) + '_' + str(num_w) + '.png', \n",
    "                    bbox_inches = \"tight\",\n",
    "                    dpi = 600)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31830215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_diff(full, tag_num):\n",
    "    # arguments: \n",
    "    # returns: \n",
    "\n",
    "    full_tag = expand_cols(full, tag_num)\n",
    "    mean = save_binned(full_tag, tag_num)\n",
    "\n",
    "    object_tag = mean['object_tag'][0]\n",
    "    num_bins = len(mean)\n",
    "\n",
    "    mean_ME = mean[(mean['mjd_binned'] < 1000)]\n",
    "    mean_NEO = mean[(mean['mjd_binned'] >= 1000)]\n",
    "\n",
    "    avg_W1_mean_ME = mean_ME['mean_W1'].mean()\n",
    "    avg_W1_mean_NEO = mean_NEO['mean_W1'].mean()\n",
    "\n",
    "    std_W1_mean_ME = np.std(mean_ME['mean_W1'])\n",
    "    std_W1_mean_NEO = np.std(mean_NEO['mean_W1'])\n",
    "    \n",
    "    avg_W2_mean_ME = mean_ME['mean_W2'].mean()\n",
    "    avg_W2_mean_NEO = mean_NEO['mean_W2'].mean()\n",
    "\n",
    "    std_W2_mean_ME = np.std(mean_ME['mean_W2'])\n",
    "    std_W2_mean_NEO = np.std(mean_NEO['mean_W2'])\n",
    "    \n",
    "    avg_W1_mean = mean['mean_W1'].mean()\n",
    "    std_W1_mean = np.std(mean['mean_W1'])\n",
    "\n",
    "    avg_W2_mean = mean['mean_W2'].mean()\n",
    "    std_W2_mean = np.std(mean['mean_W2'])\n",
    "    \n",
    "    diff_W1 = avg_W1_mean_ME - avg_W1_mean_NEO\n",
    "    diff_W2 = avg_W2_mean_ME - avg_W2_mean_NEO\n",
    "\n",
    "    # add this information as a row to the mean table\n",
    "    diff_table = {'object_tag': [object_tag],\n",
    "                  'num_bins': [num_bins],\n",
    "                  \n",
    "                  'diff_W1': [diff_W1],\n",
    "                  'diff_W2': [diff_W2],\n",
    "                  \n",
    "                  'avg_W1': [avg_W1_mean],\n",
    "                  'std_w1': [std_W1_mean],\n",
    "                  \n",
    "                  'avg_w2': [avg_W2_mean],\n",
    "                  'std_w2': [std_W2_mean],\n",
    "                  \n",
    "                  'avg_W1_ME': [avg_W1_mean_ME],\n",
    "                  'avg_W1_NEO': [avg_W1_mean_NEO],\n",
    "                  'std_W1_ME': [std_W1_mean_ME],\n",
    "                  'std_W1_NEO': [std_W1_mean_NEO],\n",
    "                  \n",
    "                  'avg_W2_ME': [avg_W2_mean_ME],\n",
    "                  'avg_W2_NEO': [avg_W2_mean_NEO],\n",
    "                  'std_W2_ME': [std_W2_mean_ME],\n",
    "                  'std_W2_NEO': [std_W2_mean_NEO]\n",
    "                 }\n",
    "                  \n",
    "    return(pd.DataFrame(data = diff_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "616c388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson_table(ultimate_mean):\n",
    "    # arguments = ultimate mean table from one of the groups\n",
    "    # returns = table with Pearson coefficent for each of the objects in the ultimate table\n",
    "\n",
    "    Pr_table = pd.DataFrame(columns = ['object_tag', 'num_obj', 'Pr'])\n",
    "    count = 0\n",
    "\n",
    "    for t in np.unique(ultimate_mean['object_tag']):\n",
    "\n",
    "        Pr_t = ultimate_mean[(ultimate_mean['object_tag'] == t)]\n",
    "\n",
    "        W1 = Pr_t['mean_W1'].to_numpy()\n",
    "        W2 = Pr_t['mean_W2'].to_numpy()\n",
    "\n",
    "        Pr = np.corrcoef(x = W2, y = W1, rowvar = False)[0][1]\n",
    "        # returns a 2 x 2 matrix with the correlation between W1 and W2. the diagonal will be 1 since it is the correlation\n",
    "        # between one variable and itself. therefore, we select a box not in the diagonal for our Pr measurement\n",
    "        \n",
    "        n_obj = Pr_t.shape[0] # measure number of rows in the dataframe\n",
    "        # this tells us the number of objects the coefficient calculation is based on\n",
    "\n",
    "        Pr_table.loc[len(Pr_table.index)] = [t, n_obj, Pr]\n",
    "        count += 1\n",
    "        \n",
    "        if(count % 5000 == 0):\n",
    "            print(str(count) + ' voids')\n",
    "        \n",
    "    return(Pr_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "423a2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson_table_separated(ultimate_mean):\n",
    "    # arguments = ultimate mean table from one of the groups\n",
    "    # returns = table with Pearson coefficent for each of the objects in the ultimate table\n",
    "\n",
    "    Pr_table = pd.DataFrame(columns = ['object_tag', 'Pr', 'Pr_MEP', 'Pr_NEO', \n",
    "                                       'num_obj', 'num_MEP', 'num_NEO'])\n",
    "    count = 0\n",
    "\n",
    "    for t in np.unique(ultimate_mean['object_tag']):\n",
    "\n",
    "        Pr_t = ultimate_mean[(ultimate_mean['origin_binned'] == t)]\n",
    "        \n",
    "        if(len(Pr_t) > 3):\n",
    "\n",
    "            W1 = Pr_t['mean_W1'].to_numpy()\n",
    "            W2 = Pr_t['mean_W2'].to_numpy()\n",
    "\n",
    "            Pr = np.corrcoef(x = W2, y = W1, rowvar = False)[0][1]\n",
    "            # returns a 2 x 2 matrix with the correlation between W1 and W2. the diagonal will be 1 since it is the correlation\n",
    "            # between one variable and itself. therefore, we select a box not in the diagonal for our Pr measurement\n",
    "\n",
    "            n_obj = Pr_t.shape[0] # measure number of rows in the dataframe\n",
    "            # this tells us the number of objects the coefficient calculation is based on\n",
    "\n",
    "            # ---------------\n",
    "\n",
    "            Pr_t_MEP = Pr_t[(Pr_t['origin_binned'] == 'MEP')]\n",
    "\n",
    "            W1_MEP = Pr_t_MEP['mean_W1'].to_numpy()\n",
    "            W2_MEP = Pr_t_MEP['mean_W2'].to_numpy()\n",
    "\n",
    "            Pr_MEP = np.corrcoef(x = W2_MEP, y = W1_MEP, rowvar = False)[0][1]\n",
    "\n",
    "            n_MEP = Pr_t_MEP.shape[0]\n",
    "\n",
    "            # ---------------\n",
    "\n",
    "            Pr_t_NEO = Pr_t[(Pr_t['origin_binned'] == 'NEO')]\n",
    "\n",
    "            W1_NEO = Pr_t_NEO['mean_W1'].to_numpy()\n",
    "            W2_NEO = Pr_t_NEO['mean_W2'].to_numpy()\n",
    "\n",
    "            Pr_NEO = np.corrcoef(x = W2_NEO, y = W1_NEO, rowvar = False)[0][1]\n",
    "\n",
    "            n_NEO = Pr_t_NEO.shape[0]\n",
    "\n",
    "            # ---------------\n",
    "\n",
    "            Pr_table.loc[len(Pr_table.index)] = [t, Pr, Pr_MEP, Pr_NEO,\n",
    "                                                 n_obj, n_MEP, n_NEO]\n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "        if(count % 5000 == 0):\n",
    "            print(str(count) + ' voids')\n",
    "        \n",
    "    return(Pr_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27fcdbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4219877264537346"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [-2.1, -1, 4.3]\n",
    "np.std(a, ddof = 1) # Standard deviation = variance = variability amplitude!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e90828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_AGN_table(ultimate_mean):\n",
    "    # arguments = ultimate mean table from one of the groups\n",
    "    # returns = table with Pearson coefficent for each of the objects in the ultimate table\n",
    "\n",
    "    pAGN_table = pd.DataFrame(columns = ['object_tag', 'num_obj', 'percentAGN', 'error'])\n",
    "    count = 0\n",
    "\n",
    "    for t in np.unique(ultimate_mean['object_tag']):\n",
    "\n",
    "        pAGN_t = ultimate_mean[(ultimate_mean['object_tag'] == t)]\n",
    "\n",
    "        pAGN = round(len(pAGN_t[(pAGN_t['mean_color'] >= 0.8)]) / len(pAGN_t) * 100, 3)\n",
    "        err = get_err_percent_num(len(pAGN_t[(pAGN_t['mean_color'] >= 0.8)]), len(pAGN_t))\n",
    "\n",
    "        n_obj = len(pAGN_t) # measure number of rows in the dataframe\n",
    "        # this tells us the number of objects the coefficient calculation is based on\n",
    "\n",
    "        pAGN_table.loc[len(pAGN_table.index)] = [t, n_obj, pAGN, err]\n",
    "        count += 1\n",
    "        \n",
    "        if(count % 5000 == 0):\n",
    "            print(str(count) + ' galaxies')\n",
    "        \n",
    "    return(pAGN_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb6f5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_Mateos(outliers_removed, colors, t):\n",
    "    \n",
    "    this_colors = colors[(colors['object_tag'] == t)]\n",
    "    \n",
    "    if(len(this_colors) > 0):\n",
    "    \n",
    "        W3 = float(this_colors['w3mpro'])\n",
    "\n",
    "        # only happens if there are color rows!\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        y = 'mean_color'\n",
    "        x = 'mean_W2'\n",
    "\n",
    "        row_list = list(range(len(outliers_removed)))\n",
    "\n",
    "        # points must have values that are within all three lines making up the wedge\n",
    "\n",
    "        for i in row_list:\n",
    "\n",
    "            if(\n",
    "                (outliers_removed.iloc[i][y] > (0.315 * (outliers_removed.iloc[i][x] - W3) - 0.222)) and\n",
    "                (outliers_removed.iloc[i][y] < (0.315 * (outliers_removed.iloc[i][x] - W3) + 0.796)) and\n",
    "                (outliers_removed.iloc[i][y] > (-3.172 * (outliers_removed.iloc[i][x] - W3) + 7.624))\n",
    "            ):\n",
    "\n",
    "                count += 1\n",
    "                \n",
    "        return(count)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7615d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_percent_AGN_table(ultimate_mean, colors):\n",
    "    # arguments = ultimate mean table from one of the groups\n",
    "    # returns = table with Pearson coefficent for each of the objects in the ultimate table\n",
    "\n",
    "    pAGN_table = pd.DataFrame(columns = ['object_tag', 'num_obj', \n",
    "                                         'percentAGN', 'error_pAGN', \n",
    "                                         'percentBlue', 'error_Blue', \n",
    "                                         'percentMateos', 'error_Mateos'\n",
    "                                        ])\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for t in np.unique(ultimate_mean['object_tag']):\n",
    "\n",
    "        pAGN_t = ultimate_mean[(ultimate_mean['object_tag'] == t)]\n",
    "        n_obj = len(pAGN_t)\n",
    "        \n",
    "        # ----------------\n",
    "\n",
    "        pAGN = round(len(pAGN_t[(pAGN_t['mean_color'] >= 0.8)]) / n_obj * 100, 3)\n",
    "        err_pAGN = get_err_percent_num(len(pAGN_t[(pAGN_t['mean_color'] >= 0.8)]), n_obj)\n",
    "        \n",
    "        pBlue = round(len(pAGN_t[(pAGN_t['mean_color'] < 0.5)]) / n_obj * 100, 3)\n",
    "        err_pBlue = get_err_percent_num(len(pAGN_t[(pAGN_t['mean_color'] < 0.5)]), n_obj)\n",
    "        \n",
    "        pMateos = round(number_Mateos(pAGN_t, colors, t) / n_obj * 100, 3)\n",
    "        err_pMateos = get_err_percent_num(number_Mateos(pAGN_t, colors, t), n_obj)\n",
    "\n",
    "        # ----------------\n",
    "        \n",
    "        pAGN_table.loc[len(pAGN_table.index)] = [t, n_obj, \n",
    "                                                 pAGN, err_pAGN,\n",
    "                                                 pBlue, err_pBlue,\n",
    "                                                 pMateos, err_pMateos\n",
    "                                                ]\n",
    "        count += 1\n",
    "        \n",
    "        if(count % 5000 == 0):\n",
    "            print(str(count) + ' galaxies')\n",
    "        \n",
    "    return(pAGN_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5104bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean(n, column_voids, column_walls, ax):\n",
    "    \n",
    "    ax[n].axvline(x = column_voids.mean(), \n",
    "              color = 'blue', \n",
    "              linewidth = 2.5, \n",
    "              label = 'mean void')\n",
    "    ax[n].axvline(x = column_voids.mean() + np.std(column_voids), \n",
    "              color = 'blue', \n",
    "              linestyle = 'dashed',\n",
    "              linewidth = 2, \n",
    "              label = 'mean void Â± std')\n",
    "    ax[n].axvline(x = column_voids.mean() - np.std(column_voids), \n",
    "              color = 'blue', \n",
    "              linestyle = 'dashed',\n",
    "              linewidth = 2)\n",
    "\n",
    "    ax[n].axvline(x = column_walls.mean(), \n",
    "              color = 'dimgray', \n",
    "              linewidth = 2.5, \n",
    "              label = 'mean void')\n",
    "    ax[n].axvline(x = column_walls.mean() + np.std(column_walls), \n",
    "              color = 'dimgray', \n",
    "              linestyle = 'dashed',\n",
    "              linewidth = 2, \n",
    "              label = 'mean void Â± std')\n",
    "    ax[n].axvline(x = column_walls.mean() - np.std(column_walls), \n",
    "              color = 'dimgray', \n",
    "              linestyle = 'dashed',\n",
    "              linewidth = 2)\n",
    "    \n",
    "    ax[n].text(-0.5, -0.0075, 'mean voids = ' + str(round(column_voids.mean(), 2)) + ' Â± ' + \n",
    "               str(round(np.std(column_voids), 2)), ha = 'left')\n",
    "    ax[n].text(-0.5, -0.0095, 'mean walls = ' + str(round(column_walls.mean(), 2)) + ' Â± ' + \n",
    "               str(round(np.std(column_walls), 2)), ha = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc4044dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_color(n, column_voids, column_walls, color_v, color_w, ax, label):\n",
    "    \n",
    "    ax[n].axvline(x = column_voids.mean(), \n",
    "              color = color_v, \n",
    "              linewidth = 2.5, \n",
    "              label = 'mean void')\n",
    "    ax[n].axvline(x = column_voids.mean() + np.std(column_voids), \n",
    "              color = color_v, \n",
    "              linestyle = 'dashed',\n",
    "              linewidth = 2, \n",
    "              label = 'mean void Â± std')\n",
    "    ax[n].axvline(x = column_voids.mean() - np.std(column_voids), \n",
    "              color = color_v, \n",
    "              linestyle = 'dashed',\n",
    "              linewidth = 2)\n",
    "\n",
    "    ax[n].axvline(x = column_walls.mean(), \n",
    "              color = color_w, \n",
    "              linewidth = 2.5, \n",
    "              label = 'mean void')\n",
    "    ax[n].axvline(x = column_walls.mean() + np.std(column_walls), \n",
    "              color = color_w, \n",
    "              linestyle = 'dashed',\n",
    "              linewidth = 2, \n",
    "              label = 'mean void Â± std')\n",
    "    ax[n].axvline(x = column_walls.mean() - np.std(column_walls), \n",
    "              color = color_w, \n",
    "              linestyle = 'dashed',\n",
    "              linewidth = 2)\n",
    "    if(label):\n",
    "        ax[n].text(-0.5, -0.0075, 'mean voids = ' + str(round(column_voids.mean(), 2)) + ' Â± ' + \n",
    "                   str(round(np.std(column_voids), 2)), ha = 'left')\n",
    "        ax[n].text(-0.5, -0.0095, 'mean walls = ' + str(round(column_walls.mean(), 2)) + ' Â± ' + \n",
    "                   str(round(np.std(column_walls), 2)), ha = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2200d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-plotted values\n",
    "def filter_walls(sample, x_low, x_high, y_low, y_high):\n",
    "    \n",
    "    sample = sample[(sample['M_r'] >= y_low) &\n",
    "                    (sample['M_r'] <= y_high) &\n",
    "                    (sample['z'] >= x_low) &\n",
    "                    (sample['z'] <= x_high)]\n",
    "    \n",
    "    return(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8e6689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_voids(sample, x_low, x_high, y_low, y_high):\n",
    "    \n",
    "    sample = sample[(sample['M_r_NYU'] >= y_low) &\n",
    "                    (sample['M_r_NYU'] <= y_high) &\n",
    "                    (sample['z'] >= x_low) &\n",
    "                    (sample['z'] <= x_high)]\n",
    "    \n",
    "    return(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "434f2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-plotted values\n",
    "def filter_new(sample, x_low, x_high, y_low, y_high):\n",
    "    \n",
    "    sample = sample[(sample['rabsmag_NSA'] >= y_low) &\n",
    "                    (sample['rabsmag_NSA'] <= y_high) &\n",
    "                    (sample['Z'] >= x_low) &\n",
    "                    (sample['Z'] <= x_high)]\n",
    "    \n",
    "    return(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34892921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out rows where no WISE object was found\n",
    "\n",
    "def filter_colors(data):\n",
    "    # arguments: table from read_data()\n",
    "    # returns: table where all snr rows are greater than 3, and without the rows containing \"NA\" for ra and dec\n",
    "    \n",
    "    data_filtered = data.dropna(subset = ['ra', 'dec'])\n",
    "    \n",
    "    data_filtered = data_filtered[(data_filtered['w1snr'] >= 5) &\n",
    "                                  (data_filtered['w2snr'] >= 5)]\n",
    "\n",
    "    return(data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aab6fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nona(df, colors):\n",
    "    \n",
    "    df_merged = df.merge(colors, how = 'left', on = 'object_tag')\n",
    "    df_nona = df_merged.dropna(subset = ['W1-W2'])\n",
    "    \n",
    "    og_len = len(df)\n",
    "    filt_len = len(df_nona)\n",
    "    \n",
    "    print(\"fraction lost = \" + str(round(1 - (filt_len / og_len), 6)))\n",
    "    \n",
    "    return(df_nona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6f85e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nona_double(df, colors):\n",
    "    \n",
    "    df_merged = df.merge(colors, how = 'left', on = 'object_tag')\n",
    "    df_nona = df_merged.dropna(subset = ['W1-W2'])\n",
    "    df_nona2 = df_nona.dropna(subset = ['W2-W3'])\n",
    "    \n",
    "    og_len = len(df)\n",
    "    filt_len = len(df_nona2)\n",
    "    \n",
    "    print(\"fraction lost = \" + str(round(1 - (filt_len / og_len), 6)))\n",
    "    \n",
    "    return(df_nona2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3649972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_err_frac(x, y):\n",
    "    # arguments: any quantity with a dividend and divisor\n",
    "    # returns: a string containing the associated error for the quotient\n",
    "    \n",
    "    if(x == 0 or y == 0):\n",
    "        \n",
    "        num_error = '???'\n",
    "        return(\" Â± \" + num_error)\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        num_error = math.sqrt((1 / x) + (1 / y)) * (x/y)\n",
    "        return(\" Â± \" + str(round(num_error, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "147c9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_err_percent(x, y):\n",
    "    # arguments: any quantity with a dividend and divisor\n",
    "    # returns: a string containing the associated error for the quotient\n",
    "    \n",
    "    if(x == 0 or y == 0):\n",
    "        \n",
    "        return(\"\")\n",
    "    \n",
    "    if(x/y == 1.0):\n",
    "        \n",
    "        return(\"\") \n",
    "        \n",
    "    else:\n",
    "    \n",
    "        num_error = math.sqrt((1 / x) + (1 / y)) * (x/y)\n",
    "        return(\" Â± \" + str(round(num_error * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64609ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_err_percent_num(x, y):\n",
    "    # arguments: any quantity with a dividend and divisor\n",
    "    # returns: a string containing the associated error for the quotient\n",
    "    \n",
    "    if(x == 0 or y == 0):\n",
    "        \n",
    "        return(0.0)\n",
    "    \n",
    "    if(x/y == 1.0):\n",
    "        \n",
    "        return(0.0) \n",
    "        \n",
    "    else:\n",
    "    \n",
    "        num_error = math.sqrt((1 / x) + (1 / y)) * (x/y)\n",
    "        return(round(num_error * 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f79f2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR BOUND MAY BE INCORRECT\n",
    "def get_fraction(sample, column, compare, r_threshold):\n",
    "\n",
    "    if(compare == '>'):\n",
    "        \n",
    "        frac = len(sample[(sample[column] > r_threshold)]) / len(sample)\n",
    "        err = get_err(len(sample[(sample[column] > r_threshold)]), len(sample))\n",
    "        \n",
    "    elif(compare == '>='):\n",
    "        \n",
    "        frac = len(sample[(sample[column] >= r_threshold)]) / len(sample)\n",
    "        err = get_err(len(sample[(sample[column] >= r_threshold)]), len(sample))\n",
    "        \n",
    "    elif(compare == '<'):\n",
    "        \n",
    "        frac = len(sample[(sample[column] < r_threshold)]) / len(sample)\n",
    "        err = get_err(len(sample[(sample[column] < r_threshold)]), len(sample))\n",
    "\n",
    "    return(str(round(frac, 3)) + err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17ee5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent(sample, column, compare, r_threshold, parenthesis):\n",
    "\n",
    "    if(compare == '>'):\n",
    "        \n",
    "        frac = len(sample[(sample[column] > r_threshold)]) / len(sample)\n",
    "        err = get_err_percent(len(sample[(sample[column] > r_threshold)]), len(sample))\n",
    "        \n",
    "    elif(compare == '>='):\n",
    "        \n",
    "        frac = len(sample[(sample[column] >= r_threshold)]) / len(sample)\n",
    "        err = get_err_percent(len(sample[(sample[column] >= r_threshold)]), len(sample))\n",
    "        \n",
    "    elif(compare == '<'):\n",
    "        \n",
    "        frac = len(sample[(sample[column] < r_threshold)]) / len(sample)\n",
    "        err = get_err_percent(len(sample[(sample[column] < r_threshold)]), len(sample))\n",
    "\n",
    "    if(parenthesis):\n",
    "        \n",
    "        return(\" (\" + str(round(frac * 100, 2)) + err + \")\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return(str(round(frac * 100, 2)) + err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01446a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(sample, column, compare, r_threshold):\n",
    "\n",
    "    if(compare == '>'):\n",
    "        \n",
    "        count = len(sample[(sample[column] > r_threshold)])\n",
    "        \n",
    "    elif(compare == '>='):\n",
    "        \n",
    "        count = len(sample[(sample[column] >= r_threshold)])\n",
    "        \n",
    "    elif(compare == '<'):\n",
    "        \n",
    "        count = len(sample[(sample[column] < r_threshold)])\n",
    "\n",
    "    return(str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae118c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(column):\n",
    "\n",
    "    mean = round(column.mean(), 3)\n",
    "    err = round(np.std(column), 3)\n",
    "\n",
    "    return(str(mean) + \" Â± \" + str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0c0c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp():\n",
    "    return str(datetime.now().strftime(\"%m-%d-%y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c0ff136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_1(voids_parent, walls_parent, title):\n",
    "    \n",
    "    title = ' ' + title\n",
    "\n",
    "    voids50 = voids_parent[(voids_parent['Pr'] > 0.50)]\n",
    "    voids75 = voids_parent[(voids_parent['Pr'] > 0.75)]\n",
    "    voids85 = voids_parent[(voids_parent['Pr'] > 0.85)]\n",
    "\n",
    "    walls50 = walls_parent[(walls_parent['Pr'] > 0.50)]\n",
    "    walls75 = walls_parent[(walls_parent['Pr'] > 0.75)]\n",
    "    walls85 = walls_parent[(walls_parent['Pr'] > 0.85)]\n",
    "\n",
    "    blank = [' ', ' ', ' ', ' ', ' ', ' ']\n",
    "\n",
    "    percent_table = pd.DataFrame(\n",
    "        [\n",
    "            ['(Parent)' + title + ' voids', \n",
    "             len(voids_parent), \n",
    "             get_percent(voids_parent, 'Pr', '>', -100, False),\n",
    "             get_mean(voids_parent['W1-W2']),\n",
    "             get_percent(voids_parent, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids_parent, 'W1-W2', '>=', 0.80) + get_percent(voids_parent, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            ['(Parent)' + title + ' walls', \n",
    "             len(walls_parent), \n",
    "             get_percent(walls_parent, 'Pr', '>', -100, False),\n",
    "             get_mean(walls_parent['W1-W2']),\n",
    "             get_percent(walls_parent, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls_parent, 'W1-W2', '>=', 0.80) + get_percent(walls_parent, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.50)', \n",
    "             len(voids50), \n",
    "             get_percent(voids_parent, 'Pr', '>', 0.50, False),\n",
    "             get_mean(voids50['W1-W2']),\n",
    "             get_percent(voids50, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids50, 'W1-W2', '>=', 0.80) + get_percent(voids50, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.50)', \n",
    "             len(walls50), \n",
    "             get_percent(walls_parent, 'Pr', '>', 0.50, False),\n",
    "             get_mean(walls50['W1-W2']),\n",
    "             get_percent(walls50, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls50, 'W1-W2', '>=', 0.80) + get_percent(walls50, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.75)', \n",
    "             len(voids75), \n",
    "             get_percent(voids_parent, 'Pr', '>', 0.75, False),\n",
    "             get_mean(voids75['W1-W2']),\n",
    "             get_percent(voids75, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids75, 'W1-W2', '>=', 0.80) + get_percent(voids75, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.75)', \n",
    "             len(walls75), \n",
    "             get_percent(walls_parent, 'Pr', '>', 0.75, False),\n",
    "             get_mean(walls75['W1-W2']),\n",
    "             get_percent(walls75, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls75, 'W1-W2', '>=', 0.80) + get_percent(walls75, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.85)', \n",
    "             len(voids85), \n",
    "             get_percent(voids_parent, 'Pr', '>', 0.85, False),\n",
    "             get_mean(voids85['W1-W2']),\n",
    "             get_percent(voids85, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids85, 'W1-W2', '>=', 0.80) + get_percent(voids85, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.85)', \n",
    "             len(walls85), \n",
    "             get_percent(walls_parent, 'Pr', '>', 0.85, False),\n",
    "             get_mean(walls85['W1-W2']),\n",
    "             get_percent(walls85, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls85, 'W1-W2', '>=', 0.80) + get_percent(walls85, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "        ],\n",
    "\n",
    "        columns = ['Galaxy group', \n",
    "                   'Total count',\n",
    "                   'Percent of parent',\n",
    "                   'Mean W1 - W2',\n",
    "                   'W1 - W2 < 0.5',\n",
    "                   'W1 - W2 >= 0.8'\n",
    "                  ]\n",
    "            )\n",
    "\n",
    "    display(HTML(percent_table.to_html(index = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41bc8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coronal_count(sample, coronal, new):\n",
    "    \n",
    "    if(not new):\n",
    "        merge = sample.merge(coronal, how = 'left', on = ['plate', 'fiber', 'mjd'])\n",
    "        merge = merge.dropna(subset = ['RA'])\n",
    "    else:\n",
    "        merge = sample.merge(coronal, how = 'left', on = ['PLATE', 'FIBERID', 'MJD'])\n",
    "        merge = merge.dropna(subset = ['RA_C'])\n",
    "\n",
    "    frac = len(merge) / len(sample)\n",
    "    err = get_err_percent(len(merge), len(sample))\n",
    "        \n",
    "    return(str(len(merge)) + \" (\" + str(round(frac * 100, 2)) + err + \")\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8cef1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_1_coronal(voids_parent, walls_parent, title, coronal_short, new):\n",
    "    \n",
    "    title = ' ' + title\n",
    "\n",
    "    voids50 = voids_parent[(voids_parent['Pr'] > 0.50)]\n",
    "    voids75 = voids_parent[(voids_parent['Pr'] > 0.75)]\n",
    "    voids85 = voids_parent[(voids_parent['Pr'] > 0.85)]\n",
    "\n",
    "    walls50 = walls_parent[(walls_parent['Pr'] > 0.50)]\n",
    "    walls75 = walls_parent[(walls_parent['Pr'] > 0.75)]\n",
    "    walls85 = walls_parent[(walls_parent['Pr'] > 0.85)]\n",
    "\n",
    "    blank = [' ', ' ', ' ', ' ', ' ', ' ',' ']\n",
    "\n",
    "    percent_table = pd.DataFrame(\n",
    "        [\n",
    "            ['(Parent)' + title + ' voids', \n",
    "             len(voids_parent), \n",
    "             get_percent(voids_parent, 'Pr', '>', -100, False),\n",
    "             get_mean(voids_parent['W1-W2']),\n",
    "             get_percent(voids_parent, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids_parent, 'W1-W2', '>=', 0.80) + get_percent(voids_parent, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(voids_parent, coronal_short, new)\n",
    "            ],\n",
    "\n",
    "            ['(Parent)' + title + ' walls', \n",
    "             len(walls_parent), \n",
    "             get_percent(walls_parent, 'Pr', '>', -100, False),\n",
    "             get_mean(walls_parent['W1-W2']),\n",
    "             get_percent(walls_parent, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls_parent, 'W1-W2', '>=', 0.80) + get_percent(walls_parent, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(walls_parent, coronal_short, new)\n",
    "            ],\n",
    "\n",
    "            blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.50)', \n",
    "             len(voids50), \n",
    "             get_percent(voids_parent, 'Pr', '>', 0.50, False),\n",
    "             get_mean(voids50['W1-W2']),\n",
    "             get_percent(voids50, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids50, 'W1-W2', '>=', 0.80) + get_percent(voids50, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(voids50, coronal_short, new)\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.50)', \n",
    "             len(walls50), \n",
    "             get_percent(walls_parent, 'Pr', '>', 0.50, False),\n",
    "             get_mean(walls50['W1-W2']),\n",
    "             get_percent(walls50, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls50, 'W1-W2', '>=', 0.80) + get_percent(walls50, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(walls50, coronal_short, new)\n",
    "            ],\n",
    "\n",
    "            blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.75)', \n",
    "             len(voids75), \n",
    "             get_percent(voids_parent, 'Pr', '>', 0.75, False),\n",
    "             get_mean(voids75['W1-W2']),\n",
    "             get_percent(voids75, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids75, 'W1-W2', '>=', 0.80) + get_percent(voids75, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(voids75, coronal_short, new)\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.75)', \n",
    "             len(walls75), \n",
    "             get_percent(walls_parent, 'Pr', '>', 0.75, False),\n",
    "             get_mean(walls75['W1-W2']),\n",
    "             get_percent(walls75, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls75, 'W1-W2', '>=', 0.80) + get_percent(walls75, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(walls75, coronal_short, new)\n",
    "            ],\n",
    "\n",
    "            blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.85)', \n",
    "             len(voids85), \n",
    "             get_percent(voids_parent, 'Pr', '>', 0.85, False),\n",
    "             get_mean(voids85['W1-W2']),\n",
    "             get_percent(voids85, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids85, 'W1-W2', '>=', 0.80) + get_percent(voids85, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(voids85, coronal_short, new)\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.85)', \n",
    "             len(walls85), \n",
    "             get_percent(walls_parent, 'Pr', '>', 0.85, False),\n",
    "             get_mean(walls85['W1-W2']),\n",
    "             get_percent(walls85, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls85, 'W1-W2', '>=', 0.80) + get_percent(walls85, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(walls85, coronal_short, new)\n",
    "            ],\n",
    "        ],\n",
    "\n",
    "        columns = ['Galaxy group', \n",
    "                   'Total count',\n",
    "                   'Percent of parent',\n",
    "                   'Mean W1 - W2',\n",
    "                   'W1 - W2 < 0.5',\n",
    "                   'W1 - W2 >= 0.8',\n",
    "                   'With coronal lines'\n",
    "                  ]\n",
    "            )\n",
    "\n",
    "    display(HTML(percent_table.to_html(index = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6b01db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rows_CC(data):\n",
    "    # arguments: table from read_data()\n",
    "    # returns: table where all snr rows are greater than 3, and without the rows containing \"NA\" for ra and dec\n",
    "    \n",
    "    data_filtered = data.dropna(subset = ['ra', 'dec'])\n",
    "    \n",
    "    data_filtered = data_filtered[(data_filtered['w1snr'] >= 5) &\n",
    "                                  (data_filtered['w2snr'] >= 5) &\n",
    "                                  (data_filtered['w3snr'] >= 3) &\n",
    "                                  (data_filtered['w4snr'] >= 3)]\n",
    "    return(data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a031ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_sm(sample, sm, to_print, new, MPA_tag):\n",
    "    \n",
    "    if(new):\n",
    "        \n",
    "        premerge = sample.merge(MPA_tag, how = 'left', on = ['PLATE', 'FIBERID', 'MJD'])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        premerge = sample\n",
    "        \n",
    "    \n",
    "    merge = premerge.merge(sm, how = 'left', on = ['MPA_tag'])\n",
    "\n",
    "    len_1 = len(merge)\n",
    "\n",
    "    merge = merge.dropna(subset = ['stellar_mass'])\n",
    "\n",
    "    len_2 = len(merge)\n",
    "    \n",
    "    len_diff = len_1 - len_2\n",
    "    \n",
    "    if (to_print & (len_1 != len_2)):\n",
    "        \n",
    "        print(\"galaxies with stellar mass: \" + str(len_2) + \" out of \" + str(len_1))\n",
    "        \n",
    "    return(get_mean(merge['stellar_mass']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3001489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_1_sm(voids_parent, walls_parent, title, coronal_short, sm, new, tag):\n",
    "    \n",
    "    title = ' ' + title\n",
    "\n",
    "    voids50 = voids_parent[(voids_parent['Pr'] > 0.50)]\n",
    "    voids75 = voids_parent[(voids_parent['Pr'] > 0.75)]\n",
    "    voids85 = voids_parent[(voids_parent['Pr'] > 0.85)]\n",
    "\n",
    "    walls50 = walls_parent[(walls_parent['Pr'] > 0.50)]\n",
    "    walls75 = walls_parent[(walls_parent['Pr'] > 0.75)]\n",
    "    walls85 = walls_parent[(walls_parent['Pr'] > 0.85)]\n",
    "\n",
    "    blank = [' ', ' ', ' ', ' ', ' ', ' ',' ',' ']\n",
    "\n",
    "    percent_table = pd.DataFrame(\n",
    "        [\n",
    "            ['(Parent)' + title + ' voids', \n",
    "             len(voids_parent), \n",
    "             get_percent(voids_parent, 'Pr', '>', -100, False),\n",
    "             get_mean(voids_parent['W1-W2']),\n",
    "             get_percent(voids_parent, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids_parent, 'W1-W2', '>=', 0.80) + get_percent(voids_parent, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(voids_parent, coronal_short, new),\n",
    "             get_mean_sm(voids_parent, sm, True, new, tag)\n",
    "            ],\n",
    "\n",
    "            ['(Parent)' + title + ' walls', \n",
    "             len(walls_parent), \n",
    "             get_percent(walls_parent, 'Pr', '>', -100, False),\n",
    "             get_mean(walls_parent['W1-W2']),\n",
    "             get_percent(walls_parent, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls_parent, 'W1-W2', '>=', 0.80) + get_percent(walls_parent, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(walls_parent, coronal_short, new),\n",
    "             get_mean_sm(walls_parent, sm, True, new, tag)\n",
    "            ],\n",
    "\n",
    "            blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.50)', \n",
    "             len(voids50), \n",
    "             get_percent(voids_parent, 'Pr', '>', 0.50, False),\n",
    "             get_mean(voids50['W1-W2']),\n",
    "             get_percent(voids50, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids50, 'W1-W2', '>=', 0.80) + get_percent(voids50, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(voids50, coronal_short, new),\n",
    "             get_mean_sm(voids50, sm, False, new, tag)\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.50)', \n",
    "             len(walls50), \n",
    "             get_percent(walls_parent, 'Pr', '>', 0.50, False),\n",
    "             get_mean(walls50['W1-W2']),\n",
    "             get_percent(walls50, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls50, 'W1-W2', '>=', 0.80) + get_percent(walls50, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(walls50, coronal_short, new),\n",
    "             get_mean_sm(walls50, sm, False, new, tag)\n",
    "            ],\n",
    "\n",
    "            blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.75)', \n",
    "             len(voids75), \n",
    "             get_percent(voids_parent, 'Pr', '>', 0.75, False),\n",
    "             get_mean(voids75['W1-W2']),\n",
    "             get_percent(voids75, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids75, 'W1-W2', '>=', 0.80) + get_percent(voids75, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(voids75, coronal_short, new),\n",
    "             get_mean_sm(voids75, sm, False, new, tag)\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.75)', \n",
    "             len(walls75), \n",
    "             get_percent(walls_parent, 'Pr', '>', 0.75, False),\n",
    "             get_mean(walls75['W1-W2']),\n",
    "             get_percent(walls75, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls75, 'W1-W2', '>=', 0.80) + get_percent(walls75, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(walls75, coronal_short, new),\n",
    "             get_mean_sm(walls75, sm, False, new, tag)\n",
    "            ],\n",
    "\n",
    "            blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.85)', \n",
    "             len(voids85), \n",
    "             get_percent(voids_parent, 'Pr', '>', 0.85, False),\n",
    "             get_mean(voids85['W1-W2']),\n",
    "             get_percent(voids85, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids85, 'W1-W2', '>=', 0.80) + get_percent(voids85, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(voids85, coronal_short, new),\n",
    "             get_mean_sm(voids85, sm, False, new, tag)\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.85)', \n",
    "             len(walls85), \n",
    "             get_percent(walls_parent, 'Pr', '>', 0.85, False),\n",
    "             get_mean(walls85['W1-W2']),\n",
    "             get_percent(walls85, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls85, 'W1-W2', '>=', 0.80) + get_percent(walls85, 'W1-W2', '>=', 0.80, True),\n",
    "             get_coronal_count(walls85, coronal_short, new),\n",
    "             get_mean_sm(walls85, sm, False, new, tag)\n",
    "            ],\n",
    "        ],\n",
    "\n",
    "        columns = ['Galaxy group', \n",
    "                   'Total count',\n",
    "                   'Percent of parent',\n",
    "                   'Mean W1 - W2',\n",
    "                   'W1 - W2 < 0.5',\n",
    "                   'W1 - W2 >= 0.8',\n",
    "                   'With coronal lines',\n",
    "                   'Mean stellar mass'\n",
    "                  ]\n",
    "            )\n",
    "\n",
    "    display(HTML(percent_table.to_html(index = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95a0cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_na_W3(sample):\n",
    "    \n",
    "    print(len(sample))\n",
    "    sample_nona = sample.dropna(subset = ['W2-W3'])\n",
    "    print(len(sample_nona))\n",
    "    print('')\n",
    "\n",
    "    return sample_nona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce477612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_r85(sample):\n",
    "    \n",
    "    print(len(sample))\n",
    "    sample_r85 = sample[(sample['Pr'] > 0.85)]\n",
    "    print(len(sample_r85))\n",
    "    print('')\n",
    "\n",
    "    return sample_r85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d907ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_r85(sample):\n",
    "    \n",
    "    print(len(sample))\n",
    "    sample_r85 = sample[(sample['Pr'] <= 0.85)]\n",
    "    print(len(sample_r85))\n",
    "    print('')\n",
    "\n",
    "    return sample_r85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1403f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_newdata(file_string):\n",
    "    \n",
    "    file = pd.read_csv('/Users/anisharadhey/Dropbox/voids_Anish/Data/' + file_string + '.csv')\n",
    "    print('read ' + file_string)\n",
    "        \n",
    "    return(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45d9092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_1_svrsef(voids_parent, walls_parent, title):\n",
    "    \n",
    "    title = ' ' + title\n",
    "\n",
    "    voids50 = voids_parent[(voids_parent['Pr'] > 0.50)]\n",
    "    voids75 = voids_parent[(voids_parent['Pr'] > 0.75)]\n",
    "    voids85 = voids_parent[(voids_parent['Pr'] > 0.85)]\n",
    "\n",
    "    walls50 = walls_parent[(walls_parent['Pr'] > 0.50)]\n",
    "    walls75 = walls_parent[(walls_parent['Pr'] > 0.75)]\n",
    "    walls85 = walls_parent[(walls_parent['Pr'] > 0.85)]\n",
    "\n",
    "    blank = [' ', ' ', ' ', ' ']\n",
    "\n",
    "    percent_table = pd.DataFrame(\n",
    "        [\n",
    "            ['(Parent)' + title + ' voids', \n",
    "             str(len(voids_parent)), # + ' (' + get_percent(voids_parent, 'Pr', '>', -100, False) + ')',\n",
    "             get_count(voids_parent, 'W1-W2', '<', 0.5) + get_percent(voids_parent, 'W1-W2', '<', 0.5, True),\n",
    "             get_count(voids_parent, 'W1-W2', '>=', 0.80) + get_percent(voids_parent, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            ['(Parent)' + title + ' walls', \n",
    "             str(len(walls_parent)), # + ' (' + get_percent(walls_parent, 'Pr', '>', -100, False) + ')',\n",
    "             get_count(walls_parent, 'W1-W2', '<', 0.5) + get_percent(walls_parent, 'W1-W2', '<', 0.5, True),\n",
    "             get_count(walls_parent, 'W1-W2', '>=', 0.80) + get_percent(walls_parent, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "#             blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.75)', \n",
    "             str(len(voids75)) + ' (' + get_percent(voids_parent, 'Pr', '>', 0.75, False) + ')',\n",
    "             get_count(voids75, 'W1-W2', '<', 0.5) + get_percent(voids75, 'W1-W2', '<', 0.5, True),\n",
    "             get_count(voids75, 'W1-W2', '>=', 0.80) + get_percent(voids75, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.75)', \n",
    "             str(len(walls75)) + ' (' + get_percent(walls_parent, 'Pr', '>', 0.75, False) + ')',\n",
    "             get_count(walls75, 'W1-W2', '<', 0.5) + get_percent(walls75, 'W1-W2', '<', 0.5, True),\n",
    "             get_count(walls75, 'W1-W2', '>=', 0.80) + get_percent(walls75, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "#             blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.85)', \n",
    "             str(len(voids85)) + ' (' + get_percent(voids_parent, 'Pr', '>', 0.85, False) + ')',\n",
    "             get_count(voids85, 'W1-W2', '<', 0.5) + get_percent(voids85, 'W1-W2', '<', 0.5, True),\n",
    "             get_count(voids85, 'W1-W2', '>=', 0.80) + get_percent(voids85, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.85)', \n",
    "             str(len(walls85)) + ' (' + get_percent(walls_parent, 'Pr', '>', 0.85, False) + ')',\n",
    "             get_count(walls85, 'W1-W2', '<', 0.5) + get_percent(walls85, 'W1-W2', '<', 0.5, True),\n",
    "             get_count(walls85, 'W1-W2', '>=', 0.80) + get_percent(walls85, 'W1-W2', '>=', 0.80, True),\n",
    "            ],\n",
    "        ],\n",
    "\n",
    "        columns = ['Galaxy group', \n",
    "                   'Count (% of parent)',\n",
    "                   'W1 - W2 < 0.5',\n",
    "                   'W1 - W2 >= 0.8'\n",
    "                  ]\n",
    "            )\n",
    "\n",
    "    display(HTML(percent_table.to_html(index = False)))\n",
    "    return percent_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f83ec267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_1_pAGN(voids_parent, walls_parent, title, thresh):\n",
    "    \n",
    "    title = ' ' + title\n",
    "\n",
    "    voids50 = voids_parent[(voids_parent['Pr'] > 0.50)]\n",
    "    voids75 = voids_parent[(voids_parent['Pr'] > 0.75)]\n",
    "    voids85 = voids_parent[(voids_parent['Pr'] > 0.85)]\n",
    "\n",
    "    walls50 = walls_parent[(walls_parent['Pr'] > 0.50)]\n",
    "    walls75 = walls_parent[(walls_parent['Pr'] > 0.75)]\n",
    "    walls85 = walls_parent[(walls_parent['Pr'] > 0.85)]\n",
    "    \n",
    "    pAGN_threshold = thresh\n",
    "\n",
    "    percent_table = pd.DataFrame(\n",
    "        [\n",
    "            ['(Parent)' + title + ' voids', \n",
    "             str(len(voids_parent)), # + ' (' + get_percent(voids_parent, 'Pr', '>', 0.75, False) + ')',\n",
    "             get_percent(voids_parent, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids_parent, 'W1-W2', '>=', 0.80) + get_percent(voids_parent, 'W1-W2', '>=', 0.80, True),\n",
    "             get_count(voids_parent, 'percentAGN', '>=', pAGN_threshold) + get_percent(voids_parent, 'percentAGN', '>=', pAGN_threshold, True),\n",
    "            ],\n",
    "\n",
    "            ['(Parent)' + title + ' walls', \n",
    "             str(len(walls_parent)), # + ' (' + get_percent(voids_parent, 'Pr', '>', 0.75, False) + ')',\n",
    "             get_percent(walls_parent, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls_parent, 'W1-W2', '>=', 0.80) + get_percent(walls_parent, 'W1-W2', '>=', 0.80, True),\n",
    "             get_count(walls_parent, 'percentAGN', '>=', pAGN_threshold) + get_percent(walls_parent, 'percentAGN', '>=', pAGN_threshold, True),\n",
    "            ],\n",
    "\n",
    "#             blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.75)', \n",
    "             str(len(voids75)) + ' (' + get_percent(voids_parent, 'Pr', '>', 0.75, False) + ')',\n",
    "             get_percent(voids75, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids75, 'W1-W2', '>=', 0.80) + get_percent(voids75, 'W1-W2', '>=', 0.80, True),\n",
    "             get_count(voids75, 'percentAGN', '>=', pAGN_threshold) + get_percent(voids75, 'percentAGN', '>=', pAGN_threshold, True),\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.75)', \n",
    "             str(len(walls75)) + ' (' + get_percent(voids_parent, 'Pr', '>', 0.75, False) + ')',\n",
    "             get_percent(walls75, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls75, 'W1-W2', '>=', 0.80) + get_percent(walls75, 'W1-W2', '>=', 0.80, True),\n",
    "             get_count(walls75, 'percentAGN', '>=', pAGN_threshold) + get_percent(walls75, 'percentAGN', '>=', pAGN_threshold, True),\n",
    "            ],\n",
    "\n",
    "#             blank,\n",
    "\n",
    "            ['Variable' + title + ' voids (r > 0.85)', \n",
    "             str(len(voids85)) + ' (' + get_percent(voids_parent, 'Pr', '>', 0.85, False) + ')',\n",
    "             get_percent(voids85, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(voids85, 'W1-W2', '>=', 0.80) + get_percent(voids85, 'W1-W2', '>=', 0.80, True),\n",
    "             get_count(voids85, 'percentAGN', '>=', pAGN_threshold) + get_percent(voids85, 'percentAGN', '>=', pAGN_threshold, True),\n",
    "            ],\n",
    "\n",
    "            ['Variable' + title + ' walls (r > 0.85)', \n",
    "             str(len(walls85)) + ' (' + get_percent(voids_parent, 'Pr', '>', 0.85, False) + ')',\n",
    "             get_percent(walls85, 'W1-W2', '<', 0.5, False),\n",
    "             get_count(walls85, 'W1-W2', '>=', 0.80) + get_percent(walls85, 'W1-W2', '>=', 0.80, True),\n",
    "             get_count(walls85, 'percentAGN', '>=', pAGN_threshold) + get_percent(walls85, 'percentAGN', '>=', pAGN_threshold, True),\n",
    "            ],\n",
    "        ],\n",
    "\n",
    "        columns = ['Galaxy group', \n",
    "                   'Count (% of parent)',\n",
    "                   'W1 - W2 < 0.5',\n",
    "                   'W1 - W2 >= 0.8',\n",
    "                   '%AGN >= ' + str(thresh) + '%'\n",
    "                  ]\n",
    "            )\n",
    "\n",
    "    display(HTML(percent_table.to_html(index = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5be12300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
